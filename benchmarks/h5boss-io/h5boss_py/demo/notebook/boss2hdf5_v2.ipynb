{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "def load_coadds(platefile, zbestfile=None, run1d=None):\n",
    "    '''\n",
    "    Document ...\n",
    "    '''\n",
    "    #- Load spPlate data\n",
    "    fx = fits.open(platefile, memmap=False)\n",
    "    header   = fx[0].header\n",
    "    c0       = header['COEFF0']\n",
    "    c1       = header['COEFF1']\n",
    "    nwave    = header['NAXIS1']\n",
    "    nfiber   = header['NAXIS2']\n",
    "    wave     = (10**(c0 + c1*np.arange(nwave))).astype(np.float32)\n",
    "    flux     = fx[0].data\n",
    "    ivar     = fx[1].data\n",
    "    and_mask = fx[2].data\n",
    "    or_mask  = fx[3].data\n",
    "    wavedisp = fx[4].data\n",
    "    sky      = fx[6].data\n",
    "    fx.close()\n",
    "\n",
    "    if run1d is None:\n",
    "        run1d = header['RUN2D']  #- default run1d == run2d\n",
    "    \n",
    "    #- Get best fit model from zbest file\n",
    "    if zbestfile is None:\n",
    "        zbestfile = platefile.replace('spPlate', '{}/spZbest'.format(run1d))\n",
    "\n",
    "    model = fits.getdata(zbestfile, 2)\n",
    "\n",
    "    coadds = list()\n",
    "    for i in range(nfiber):\n",
    "        sp = Table()\n",
    "        sp['WAVE']     = wave               #- repeat !\n",
    "        sp['FLUX']     = flux[i]\n",
    "        sp['IVAR']     = ivar[i]\n",
    "        sp['AND_MASK'] = and_mask[i]\n",
    "        sp['OR_MASK']  = or_mask[i]\n",
    "        sp['WAVEDISP'] = wavedisp[i]\n",
    "        sp['SKY']      = sky[i]\n",
    "        sp['MODEL']    = model[i]\n",
    "        sp.meta = header\n",
    "        \n",
    "        #- TODO: Add units, comments to each column\n",
    "        \n",
    "        coadds.append(sp)\n",
    "        \n",
    "    return coadds\n",
    "\n",
    "def load_frame(framefile, cframefile=None, flatfile=None):\n",
    "    \"\"\"\n",
    "    Document ...\n",
    "    \"\"\"\n",
    "    if cframefile is None:\n",
    "        cframefile = framefile.replace('spFrame', 'spCFrame')\n",
    "        if cframefile.endswith('.gz'):\n",
    "            cframefile = cframefile[:-3]\n",
    "    import os.path\n",
    "    if os.path.exists(framefile)==False:\n",
    "       exit()\n",
    "    #- Load framefile and get original dimensions\n",
    "    eflux = fits.getdata(framefile, 0)\n",
    "    nfiber, npix = eflux.shape\n",
    "    if os.path.exists(cframefile)==False:\n",
    "     exit()        \n",
    "    #- Load spCFrame file; trim arrays back to original size\n",
    "    fx = fits.open(cframefile, memmap=False)\n",
    "    header = fx[0].header\n",
    "    flux = fx[0].data[:, 0:npix]\n",
    "    ivar = fx[1].data[:, 0:npix]\n",
    "    mask = fx[2].data[:, 0:npix]\n",
    "    wave = (10**fx[3].data[:, 0:npix]).astype(np.float32)\n",
    "    wavedisp  = fx[4].data[:, 0:npix]\n",
    "    sky    = fx[6].data[:, 0:npix]\n",
    "    x      = fx[7].data[:, 0:npix]\n",
    "    superflat = fx[8].data[:, 0:npix]\n",
    "    \n",
    "    #- Load fiberflat spFlat[0]\n",
    "    if flatfile is None:\n",
    "        flatfile = header['FLATFILE'].replace('sdR', 'spFlat')\n",
    "        flatfile = flatfile.replace('.fit', '.fits.gz')\n",
    "        filedir, basename = os.path.split(os.path.abspath(cframefile))\n",
    "        flatfile = os.path.join(filedir, flatfile)\n",
    "\n",
    "    if os.path.exists(flatfile)==False:\n",
    "      exit()\n",
    "    fiberflat = fits.getdata(flatfile, 0)\n",
    "    \n",
    "    #- Calculate calibration vector: flux = electrons * calib\n",
    "    electrons = eflux * fiberflat * superflat\n",
    "    ii = np.where(electrons != 0.0)\n",
    "    calib = np.zeros(flux.shape)\n",
    "    calib[ii] = flux[ii] / electrons[ii]\n",
    "            \n",
    "    fx.close()\n",
    "    \n",
    "    #- Assemble spectra tables\n",
    "    spectra = list()\n",
    "    for i in range(nfiber):\n",
    "        sp = Table()\n",
    "        sp['WAVE'] = wave[i]\n",
    "        sp['FLUX'] = flux[i]\n",
    "        sp['IVAR'] = ivar[i]\n",
    "        sp['MASK'] = mask[i]\n",
    "        sp['WAVEDISP'] = wavedisp[i]\n",
    "        sp['SKY'] = sky[i]\n",
    "        sp['X'] = x[i]\n",
    "        sp['CALIB'] = calib[i].astype(np.float32)\n",
    "        sp.meta = header\n",
    "        \n",
    "        #- TODO: Add units, comments to each column\n",
    "        \n",
    "        spectra.append(sp)\n",
    "        \n",
    "    return spectra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'h5boss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-31de9bd1f939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mh5boss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'h5boss'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create an HDF5 file from BOSS data\n",
    "\n",
    "TODO:\n",
    "  - include comments in meta/attrs\n",
    "  - platelist quantities\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import sys, os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import h5boss.io\n",
    "import time\n",
    "\n",
    "def serial_convert(platefile,hdf5output):\n",
    "    platefile=platefile[0]\n",
    "    hdf5output=str(hdf5output)\n",
    "    filedir = os.path.split(os.path.abspath(platefile))[0]\n",
    "    hdr = fits.getheader(platefile) \n",
    "    plate = hdr['PLATEID']\n",
    "    mjd = hdr['MJD']\n",
    "    tstart=time.time()\n",
    "    #--- Plugmap ---\n",
    "    print('plugmap')\n",
    "    plugmap = Table.read(platefile, 5)\n",
    "    dataname = '{}/{}/plugmap'.format(plate, mjd)\n",
    "    plugmap.write(hdf5output, path=dataname, append=True)\n",
    "\n",
    "    #--- zbest ---\n",
    "    print('zbest')\n",
    "    run1d = hdr['RUN2D']  #- default run1d == run2d\n",
    "    zbestfile = platefile.replace('spPlate', '{}/spZbest'.format(run1d))\n",
    "    zbest = Table.read(zbestfile, 1)\n",
    "    dataname = '{}/{}/zbest'.format(plate, mjd)\n",
    "    zbest.write(hdf5output, path=dataname, append=True)\n",
    "    nfiber = len(zbest)\n",
    "\n",
    "    #--- zall (skip) ---\n",
    "    pass\n",
    "\n",
    "    #--- zline ---\n",
    "    print('zline')\n",
    "    zlinefile = zbestfile.replace('spZbest-', 'spZline-')\n",
    "    zline = Table.read(zlinefile, 1)\n",
    "    dataname = '{}/{}/zline'.format(plate, mjd)\n",
    "    zline.write(hdf5output, path=dataname, append=True)\n",
    "\n",
    "    #--- photometric matches ---\n",
    "    print('photo')\n",
    "    photomatchfile = platefile.replace('spPlate-', 'photoMatchPlate-')\n",
    "    photomatch = Table.read(photomatchfile, 1)\n",
    "    photomatch['FIBERID'] = np.arange(1, nfiber+1, dtype=np.int16)\n",
    "    dataname = '{}/{}/photo/match'.format(plate, mjd)\n",
    "    photomatch.write(hdf5output, path=dataname, append=True)\n",
    "\n",
    "    photoposfile = platefile.replace('spPlate-', 'photoPosPlate-')\n",
    "    photopos = Table.read(photoposfile, 1)\n",
    "    photopos['FIBERID'] = np.arange(1, nfiber+1, dtype=np.int16)\n",
    "    dataname = '{}/{}/photo/matchpos'.format(plate, mjd)\n",
    "    photopos.write(hdf5output, path=dataname, append=True)\n",
    "\n",
    "    photofluxfile = platefile.replace('spPlate-', 'photoPlate-')\n",
    "    photoflux = Table.read(photofluxfile, 1)\n",
    "    photoflux['FIBERID'] = np.arange(1, nfiber+1, dtype=np.int16)\n",
    "    dataname = '{}/{}/photo/matchflux'.format(plate, mjd)\n",
    "    photoflux.write(hdf5output, path=dataname, append=True)\n",
    "\n",
    "    #--- Coadd ---\n",
    "    print('loading coadds')\n",
    "    coadds = h5boss.io.load_coadds(platefile)\n",
    "\n",
    "    print('writing coadds')\n",
    "    for i, cx in enumerate(coadds):\n",
    "        dataname = '{}/{}/{}/coadd'.format(plate, mjd, i+1)\n",
    "        cx.write(hdf5output, path=dataname, append=True)\n",
    "\n",
    "    #--- Individual exposures ---\n",
    "    #- Parse spPlancomb to get exposures that were used\n",
    "    print('parsing planfile')\n",
    "    planfile = platefile.replace('spPlate-', 'spPlancomb-').replace('.fits', '.par')\n",
    "    framefiles = list()\n",
    "    for line in open(planfile):\n",
    "        if line.startswith('SPEXP '):\n",
    "            tmp = line.split()\n",
    "            tmp = [x+'.gz' for x in tmp[7:-1]]\n",
    "            framefiles.extend(tmp)\n",
    "\n",
    "    print('individual exposures')\n",
    "    for filename in framefiles:\n",
    "        print(filename)\n",
    "        frame = h5boss.io.load_frame(filedir+'/'+filename)\n",
    "        if ('spFrame-b1' in filename) or ('spFrame-r1' in filename):\n",
    "            offset = 0\n",
    "        elif ('spFrame-b2' in filename) or ('spFrame-r2' in filename):\n",
    "            offset = 500\n",
    "        else:\n",
    "            print('huh?', filename)\n",
    "            sys.exit(1)\n",
    "\n",
    "        for i, fx in enumerate(frame):\n",
    "            br = fx.meta['CAMERAS'][0]\n",
    "            expid = fx.meta['EXPOSURE']\n",
    "            fiber = offset+i+1\n",
    "            dataname = '{}/{}/{}/exposures/{}/{}'.format(plate, mjd, fiber, expid, br)\n",
    "            fx.write(hdf5output, path=dataname, append=True)\n",
    "\n",
    "\n",
    "    tend=time.time()-tstart\n",
    "    print ('time',tend)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewrite the boss2hdf5 converter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/global/projecta/projectdirs/sdss/data/sdss/dr12/boss/spectro/redux/v5_7_0/5290/spPlate-5290-55862.fits']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sections in serial convert\n",
    "from __future__ import division, print_function\n",
    "import sys, os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import time\n",
    "datapath = \"/global/projecta/projectdirs/sdss/data/sdss/dr12/boss/spectro/redux/v5_7_0/\"\n",
    "def listfiles():\n",
    "     ldir=os.listdir(datapath)\n",
    "     lldir=[fn for fn in ldir if fn.isdigit()]\n",
    "     return lldir\n",
    "plateslist=listfiles()\n",
    "platepath_for_current_rank = datapath+plateslist[0]\n",
    "def findseed(x):\n",
    "     fitsfiles = [os.path.join(root, name)\n",
    "       for root, dirs, files in os.walk(x)\n",
    "       for name in files\n",
    "        if name.startswith(\"spPlate\") and name.endswith(\".fits\")]\n",
    "     return fitsfiles\n",
    "fitspath_name_for_current_rank = findseed(platepath_for_current_rank)\n",
    "fitspath_name_for_current_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sections in load coadd\n",
    "platefile=fitspath_name_for_current_rank[0]\n",
    "filedir = os.path.split(os.path.abspath(platefile))[0]\n",
    "hdr = fits.getheader(platefile) \n",
    "plate = hdr['PLATEID']\n",
    "mjd = hdr['MJD']\n",
    "#- Load spPlate data\n",
    "fx = fits.open(platefile, memmap=False)\n",
    "header   = fx[0].header\n",
    "c0       = header['COEFF0']\n",
    "c1       = header['COEFF1']\n",
    "nwave    = header['NAXIS1']\n",
    "nfiber   = header['NAXIS2']\n",
    "wave     = (10**(c0 + c1*np.arange(nwave))).astype(np.float32)\n",
    "flux     = fx[0].data\n",
    "ivar     = fx[1].data\n",
    "and_mask = fx[2].data\n",
    "or_mask  = fx[3].data\n",
    "wavedisp = fx[4].data\n",
    "sky      = fx[6].data\n",
    "fx.close()\n",
    "run1d = header['RUN2D']  #- default run1d == run2d\n",
    "    \n",
    "#- Get best fit model from zbest file\n",
    "zbestfile = platefile.replace('spPlate', '{}/spZbest'.format(run1d))\n",
    "model = fits.getdata(zbestfile, 2)\n",
    "coadds=(wave,flux,ivar,and_mask,or_mask,wavedisp,sky,model,header)\n",
    "hdf5output=\"h5boss_v2_15.h5\"\n",
    "dat=(\"wave\",\"flux\",\"ivar\",\"and_mask\",\"or_mask\",\"wavedisp\",\"sky\",\"model\")\n",
    "#list(header.cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copy each wavelength dataset into the hdf5 file\n",
    "import h5py\n",
    "outx=h5py.File(hdf5output,'w')\n",
    "for i in range(0,8):\n",
    "    id = '{}/{}/{}'.format(plate, mjd, dat[i])\n",
    "    dx=outx.create_dataset(id,data=coadds[i])\n",
    "    temptb=Table()\n",
    "    temptb.meta=coadds[8]\n",
    "    #temptb.write(hdf5output,id,append=True)\n",
    "    #dx.attrs.__setitem__(dat[i], coadds[8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing planfile\n",
      "individual exposures\n"
     ]
    }
   ],
   "source": [
    "#--- Individual exposures ---\n",
    "#- Parse spPlancomb to get exposures that were used\n",
    "print('parsing planfile')\n",
    "planfile = platefile.replace('spPlate-', 'spPlancomb-').replace('.fits', '.par')\n",
    "framefiles = list()\n",
    "for line in open(planfile):\n",
    "    if line.startswith('SPEXP '):\n",
    "        tmp = line.split()\n",
    "        tmp = [x+'.gz' for x in tmp[7:-1]]\n",
    "        framefiles.extend(tmp)\n",
    "\n",
    "print('individual exposures')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sections in load exposures\n",
    "def load_frame(framefile, cframefile=None, flatfile=None):\n",
    "    \"\"\"\n",
    "    Document ...\n",
    "    \"\"\"\n",
    "    if cframefile is None:\n",
    "        cframefile = framefile.replace('spFrame', 'spCFrame')\n",
    "        if cframefile.endswith('.gz'):\n",
    "            cframefile = cframefile[:-3]\n",
    "    import os.path\n",
    "    if os.path.exists(framefile)==False:\n",
    "        exit()\n",
    "    #- Load framefile and get original dimensions\n",
    "    eflux = fits.getdata(framefile, 0)\n",
    "    nfiber, npix = eflux.shape\n",
    "    if os.path.exists(cframefile)==False:\n",
    "        exit()        \n",
    "    #- Load spCFrame file; trim arrays back to original size\n",
    "    fx = fits.open(cframefile, memmap=False)\n",
    "    header = fx[0].header   # this means the exposureid is same for flux, ivar, etc\n",
    "    expid=header['EXPOSURE']\n",
    "    flux = fx[0].data[:, 0:npix]\n",
    "    ivar = fx[1].data[:, 0:npix]\n",
    "    mask = fx[2].data[:, 0:npix]\n",
    "    wave = (10**fx[3].data[:, 0:npix]).astype(np.float32)\n",
    "    wavedisp  = fx[4].data[:, 0:npix]\n",
    "    sky    = fx[6].data[:, 0:npix]\n",
    "    x      = fx[7].data[:, 0:npix]\n",
    "    superflat = fx[8].data[:, 0:npix]\n",
    "    \n",
    "    #- Load fiberflat spFlat[0]\n",
    "    if flatfile is None:\n",
    "        flatfile = header['FLATFILE'].replace('sdR', 'spFlat')\n",
    "        flatfile = flatfile.replace('.fit', '.fits.gz')\n",
    "        filedir, basename = os.path.split(os.path.abspath(cframefile))\n",
    "        flatfile = os.path.join(filedir, flatfile)\n",
    "\n",
    "    if os.path.exists(flatfile)==False:\n",
    "        exit()\n",
    "    fiberflat = fits.getdata(flatfile, 0)\n",
    "    \n",
    "    #- Calculate calibration vector: flux = electrons * calib\n",
    "    electrons = eflux * fiberflat * superflat\n",
    "    ii = np.where(electrons != 0.0)\n",
    "    calib = np.zeros(flux.shape)\n",
    "    calib[ii] = flux[ii] / electrons[ii]\n",
    "            \n",
    "    fx.close()\n",
    "    exposure=(wave,flux,ivar,mask,wavedisp,sky,x,calib.astype(np.float32), header,expid)    \n",
    "    return exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expdat=(\"wave\",\"flux\",\"ivar\",\"mask\",\"wavedisp\",\"sky\",\"x\",\"calib\")\n",
    "def dump2h5(frame1,frame2,expid,hdf5output,br):\n",
    "    import h5py\n",
    "    print ('dump:',expid)\n",
    "\n",
    "    for i in range(0,len(expdat)):\n",
    "        try:\n",
    "            outx=h5py.File(hdf5output,'w')\n",
    "        except Exception as e:\n",
    "            print (\"file open error\")\n",
    "            pass\n",
    "        id = '{}/{}/exposures/{}/{}/{}'.format(plate, mjd, expid,br,expdat[i])\n",
    "        try:\n",
    "            dset=np.append(frame1[i],frame2[i])\n",
    "            print (\"id:%s\"%id)\n",
    "            print (\"shape:\",dset.shape)\n",
    "        except Exception as e:\n",
    "            print (\"append error\")\n",
    "            pass\n",
    "        try:\n",
    "            dx=outx.create_dataset(id,data=dset)\n",
    "        except Exception as e:\n",
    "            print ('error in frame dump')\n",
    "            pass\n",
    "        #outx.flush()\n",
    "        outx.close()    \n",
    "def single_dump2h5(frame1,expid,hdf5output,br):\n",
    "    import h5py\n",
    "    print (\"single dump:\",expid)\n",
    "\n",
    "    for i in range(0,len(expdat)):\n",
    "        try:\n",
    "            outx=h5py.File(hdf5output,'w')\n",
    "        except Exception as e:\n",
    "            print (\"file open error\")\n",
    "            pass\n",
    "        id = '{}/{}/exposures/{}/{}/{}'.format(plate, mjd, expid,br,expdat[i])\n",
    "        dset=frame1[i]\n",
    "        try:\n",
    "            dx=outx.create_dataset(id,data=dset)\n",
    "        except Exception as e:\n",
    "            print ('error in frame dump')\n",
    "            pass\n",
    "        outx.flush()\n",
    "        outx.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# initialize the empty arrays, \n",
    "# b: wave, flux, ivar, mask, wavedisp, sky, x, calib, header\n",
    "# r: wave, flux, ivar, mask, wavedisp, sky, x, calib, header\n",
    "b1=0\n",
    "r1=0\n",
    "print (len(framefiles))\n",
    "frameb1=list()\n",
    "framer1=list()\n",
    "frameb2=list()\n",
    "framer2=list()\n",
    "filename=framefiles[0]\n",
    "if ('spFrame-b1' in filename):\n",
    "    frame=load_frame(filedir+'/'+filename)\n",
    "#for filename in framefiles:\n",
    "#    offset = 0  #fiber 0-499\n",
    "#    if ('spFrame-b1' in filename):\n",
    "#        try:\n",
    "#         frame=load_frame(filedir+'/'+filename)\n",
    "#         frameb1.append(frame)\n",
    "#         print (filename, frame[9])\n",
    "#        except Exception as e:\n",
    "#            print (\"File not found\")\n",
    "#            pass\n",
    "    #if ('spFrame-r1' in filename):\n",
    "    #    try:\n",
    "    #     frame=load_frame(filedir+'/'+filename)\n",
    "    #     framer1.append(frame)\n",
    "    #     print (filename, frame[9])\n",
    "    #    except Exception as e:\n",
    "    #        print (\"File not found\")\n",
    "    #        pass\n",
    "     \n",
    "\n",
    "#combine b1 and b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4112)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in framefiles:\n",
    "    offset = 500 #fiber 500-999\n",
    "    if ('spFrame-b2' in filename):\n",
    "        try:\n",
    "         frame=load_frame(filedir+'/'+filename)\n",
    "         frameb2.append(frame)\n",
    "         print (filename, frame[9])\n",
    "        except Exception as e:\n",
    "            print (\"File not found\")\n",
    "            pass                \n",
    "    if ('spFrame-r2' in filename):\n",
    "        try:\n",
    "         frame=load_frame(filedir+'/'+filename)\n",
    "         framer2.append(frame)\n",
    "         print (filename, frame[9])\n",
    "        except Exception as e:\n",
    "            print (\"File not found\")\n",
    "            pass            \n",
    "\n",
    "print (\"frameb1:%d\"%(len(frameb1)))        \n",
    "print (\"frameb2:%d\"%(len(frameb2)))        \n",
    "print (\"framer1:%d\"%(len(framer1)))        \n",
    "print (\"framer2:%d\"%(len(framer2)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'framefiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0cad08b39241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mframefiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'framefiles' is not defined"
     ]
    }
   ],
   "source": [
    "framefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(frameb1)):\n",
    "    expidb1=frameb1[i][9]\n",
    "    hit=0\n",
    "    for j in range(0,len(frameb2)):\n",
    "        expidb2=frameb2[j][9]\n",
    "        if expidb1==expidb2:\n",
    "            #combine frameb1 and frameb2\n",
    "            dump2h5(frameb1[i],frameb2[j],expidb1,hdf5output,'b')\n",
    "            frameb2.remove(frameb2[j])\n",
    "            hit=1\n",
    "            break\n",
    "    if hit==0:\n",
    "        single_dump2h5(frameb1[i],expidb1,hdf5output,'b')\n",
    "for i in range(0,len(frameb2)):\n",
    "    expidb2=frameb2[i][9]\n",
    "    single_dump2h5(frameb2[i],expidb2,hdf5output,'b')\n",
    "\n",
    "#combine r1 and r2\n",
    "for i in range(0,len(framer1)):\n",
    "    expidr1=framer1[i][9]\n",
    "    hit=0\n",
    "    for j in range(0,len(framer2)):\n",
    "        expidr2=framer2[j][9]\n",
    "        if expidr1==expidr2:\n",
    "            #combine frameb1 and frameb2\n",
    "            dump2h5(framer1[i],framer2[j],expidr1,hdf5output,'r')\n",
    "            framer2.remove(framer2[j])\n",
    "            hit=1\n",
    "            break\n",
    "    if hit==0:\n",
    "        single_dump2h5(framer1[i],expidr1,hdf5output,'r')\n",
    "for i in range(0,len(framer2)):\n",
    "    expidr2=framer2[i][9]\n",
    "    single_dump2h5(framer2[i],expidr2,hdf5output,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'spFrame-b1' in 'spCFrame-b1-00135668.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id5290/55862/exposures/135671/b/calib\n",
    "id5290/55862/exposures/135671/r/calib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
